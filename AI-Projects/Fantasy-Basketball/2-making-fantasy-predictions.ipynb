{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('tf': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b25771bb79ecddf2cd0221654ecee2da123d46bdee02f2e26773cd30025ac0c0"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Creating a prediction system for fantasy basketball points\n",
    "\n",
    "In this notebook we will create a Machine Learning architecture that will take information from previous years to predict a player's fantasy points. We will first test a few hypothesis of what statistics and information is easier to predict and then seeing how we can bring it together to make the best algorithm to predict a player's fantasy points."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We will start by first getting the data from the csv files into a pandas dataframe. Then we will edit it to remove things like NaN's. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn as sk\n",
    "import random\n",
    "\n",
    "player_tables={}\n",
    "team_tables={}\n",
    "\n",
    "years=range(2000,2021)\n",
    "player_stats=[\"player_per_game\", \"player_per_36_min\", \"per_100_possesions\"]\n",
    "team_stats=[\"team_per_game\", \"team_per_100_possesions\"]\n",
    "\n",
    "for year in years:\n",
    "    player_tables[year]={}\n",
    "    team_tables[year]={}\n",
    "    for stat in player_stats:\n",
    "        player_tables[year][stat]=pd.read_csv(\"NBA_data/NBA_\"+str(year)+\"_\"+stat+\".csv\", index_col=0)\n",
    "        player_tables[year][stat]=player_tables[year][stat].dropna()\n",
    "        player_tables[year][stat].insert(0, \"year\", year, True)\n",
    "        player_tables[year][stat]=player_tables[year][stat].rename(columns={\"player\":\"name\"}) #this is so we can search for name as a query for players or teams\n",
    "    for stat in team_stats:\n",
    "        team_tables[year][stat]=pd.read_csv(\"NBA_data/NBA_\"+str(year)+\"_\"+stat+\".csv\", index_col=0)\n",
    "        team_tables[year][stat]=team_tables[year][stat].dropna()\n",
    "        team_tables[year][stat].insert(0, \"year\", year, True)\n",
    "        team_tables[year][stat]=team_tables[year][stat].rename(columns={\"team_name\":\"name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   year                      name pos  age team_id   g  gs  mp_per_g  \\\n",
       "0  2020              Steven Adams   C   26     OKC  63  63      26.7   \n",
       "1  2020               Bam Adebayo  PF   22     MIA  72  72      33.6   \n",
       "2  2020         LaMarcus Aldridge   C   34     SAS  53  53      33.1   \n",
       "4  2020  Nickeil Alexander-Walker  SG   21     NOP  47   1      12.6   \n",
       "5  2020             Grayson Allen  SG   24     MEM  38   0      18.9   \n",
       "\n",
       "   fg_per_g  fga_per_g  ...  ft_pct.20  orb_per_g.20  drb_per_g.20  \\\n",
       "0       4.5        7.6  ...      0.582           3.3           6.0   \n",
       "1       6.1       11.0  ...      0.691           2.4           7.8   \n",
       "2       7.4       15.0  ...      0.827           1.9           5.5   \n",
       "4       2.1        5.7  ...      0.676           0.2           1.6   \n",
       "5       3.1        6.6  ...      0.867           0.2           2.0   \n",
       "\n",
       "   trb_per_g.20  ast_per_g.20  stl_per_g.20  blk_per_g.20  tov_per_g.20  \\\n",
       "0           9.3           2.3           0.8           1.1           1.5   \n",
       "1          10.2           5.1           1.1           1.3           2.8   \n",
       "2           7.4           2.4           0.7           1.6           1.4   \n",
       "4           1.8           1.9           0.4           0.2           1.1   \n",
       "5           2.2           1.4           0.3           0.1           0.9   \n",
       "\n",
       "   pf_per_g.20  pts_per_g.20  \n",
       "0          1.9          10.9  \n",
       "1          2.5          15.9  \n",
       "2          2.4          18.9  \n",
       "4          1.2           5.7  \n",
       "5          1.4           8.7  \n",
       "\n",
       "[5 rows x 610 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>name</th>\n      <th>pos</th>\n      <th>age</th>\n      <th>team_id</th>\n      <th>g</th>\n      <th>gs</th>\n      <th>mp_per_g</th>\n      <th>fg_per_g</th>\n      <th>fga_per_g</th>\n      <th>...</th>\n      <th>ft_pct.20</th>\n      <th>orb_per_g.20</th>\n      <th>drb_per_g.20</th>\n      <th>trb_per_g.20</th>\n      <th>ast_per_g.20</th>\n      <th>stl_per_g.20</th>\n      <th>blk_per_g.20</th>\n      <th>tov_per_g.20</th>\n      <th>pf_per_g.20</th>\n      <th>pts_per_g.20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020</td>\n      <td>Steven Adams</td>\n      <td>C</td>\n      <td>26</td>\n      <td>OKC</td>\n      <td>63</td>\n      <td>63</td>\n      <td>26.7</td>\n      <td>4.5</td>\n      <td>7.6</td>\n      <td>...</td>\n      <td>0.582</td>\n      <td>3.3</td>\n      <td>6.0</td>\n      <td>9.3</td>\n      <td>2.3</td>\n      <td>0.8</td>\n      <td>1.1</td>\n      <td>1.5</td>\n      <td>1.9</td>\n      <td>10.9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020</td>\n      <td>Bam Adebayo</td>\n      <td>PF</td>\n      <td>22</td>\n      <td>MIA</td>\n      <td>72</td>\n      <td>72</td>\n      <td>33.6</td>\n      <td>6.1</td>\n      <td>11.0</td>\n      <td>...</td>\n      <td>0.691</td>\n      <td>2.4</td>\n      <td>7.8</td>\n      <td>10.2</td>\n      <td>5.1</td>\n      <td>1.1</td>\n      <td>1.3</td>\n      <td>2.8</td>\n      <td>2.5</td>\n      <td>15.9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020</td>\n      <td>LaMarcus Aldridge</td>\n      <td>C</td>\n      <td>34</td>\n      <td>SAS</td>\n      <td>53</td>\n      <td>53</td>\n      <td>33.1</td>\n      <td>7.4</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>0.827</td>\n      <td>1.9</td>\n      <td>5.5</td>\n      <td>7.4</td>\n      <td>2.4</td>\n      <td>0.7</td>\n      <td>1.6</td>\n      <td>1.4</td>\n      <td>2.4</td>\n      <td>18.9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020</td>\n      <td>Nickeil Alexander-Walker</td>\n      <td>SG</td>\n      <td>21</td>\n      <td>NOP</td>\n      <td>47</td>\n      <td>1</td>\n      <td>12.6</td>\n      <td>2.1</td>\n      <td>5.7</td>\n      <td>...</td>\n      <td>0.676</td>\n      <td>0.2</td>\n      <td>1.6</td>\n      <td>1.8</td>\n      <td>1.9</td>\n      <td>0.4</td>\n      <td>0.2</td>\n      <td>1.1</td>\n      <td>1.2</td>\n      <td>5.7</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2020</td>\n      <td>Grayson Allen</td>\n      <td>SG</td>\n      <td>24</td>\n      <td>MEM</td>\n      <td>38</td>\n      <td>0</td>\n      <td>18.9</td>\n      <td>3.1</td>\n      <td>6.6</td>\n      <td>...</td>\n      <td>0.867</td>\n      <td>0.2</td>\n      <td>2.0</td>\n      <td>2.2</td>\n      <td>1.4</td>\n      <td>0.3</td>\n      <td>0.1</td>\n      <td>0.9</td>\n      <td>1.4</td>\n      <td>8.7</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 610 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "player_tables[2020][\"player_per_game\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   year   ast  blk   drb    fg   fg2  fg2_pct  fg2a   fg3  fg3_pct  ...   fta  \\\n",
       "1  2020  24.7  4.8  36.4  41.7  26.5    0.541  49.0  15.1    0.367  ...  23.8   \n",
       "2  2020  25.9  5.9  42.2  43.3  29.5    0.567  52.0  13.8    0.355  ...  24.7   \n",
       "3  2020  20.6  6.1  35.1  42.2  29.3    0.514  57.1  12.9    0.377  ...  22.1   \n",
       "4  2020  21.6  5.2  34.5  40.8  25.1    0.557  45.2  15.6    0.345  ...  26.1   \n",
       "5  2020  23.7  4.7  37.0  41.6  29.1    0.522  55.8  12.4    0.371  ...  26.3   \n",
       "\n",
       "      g     mp   orb    pf    pts  stl                     name   tov   trb  \n",
       "1  75.0  242.3  10.5  19.5  117.0  6.1        Dallas Mavericks*  12.7  46.9  \n",
       "2  73.0  241.0   9.5  19.6  118.7  7.2         Milwaukee Bucks*  15.1  51.7  \n",
       "3  74.0  241.0  10.2  21.7  115.0  6.3  Portland Trail Blazers*  12.8  45.3  \n",
       "4  72.0  241.4   9.8  21.8  117.8  8.7         Houston Rockets*  14.7  44.3  \n",
       "5  72.0  241.4  10.7  22.1  116.3  7.1    Los Angeles Clippers*  14.6  47.7  \n",
       "\n",
       "[5 rows x 25 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>ast</th>\n      <th>blk</th>\n      <th>drb</th>\n      <th>fg</th>\n      <th>fg2</th>\n      <th>fg2_pct</th>\n      <th>fg2a</th>\n      <th>fg3</th>\n      <th>fg3_pct</th>\n      <th>...</th>\n      <th>fta</th>\n      <th>g</th>\n      <th>mp</th>\n      <th>orb</th>\n      <th>pf</th>\n      <th>pts</th>\n      <th>stl</th>\n      <th>name</th>\n      <th>tov</th>\n      <th>trb</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2020</td>\n      <td>24.7</td>\n      <td>4.8</td>\n      <td>36.4</td>\n      <td>41.7</td>\n      <td>26.5</td>\n      <td>0.541</td>\n      <td>49.0</td>\n      <td>15.1</td>\n      <td>0.367</td>\n      <td>...</td>\n      <td>23.8</td>\n      <td>75.0</td>\n      <td>242.3</td>\n      <td>10.5</td>\n      <td>19.5</td>\n      <td>117.0</td>\n      <td>6.1</td>\n      <td>Dallas Mavericks*</td>\n      <td>12.7</td>\n      <td>46.9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020</td>\n      <td>25.9</td>\n      <td>5.9</td>\n      <td>42.2</td>\n      <td>43.3</td>\n      <td>29.5</td>\n      <td>0.567</td>\n      <td>52.0</td>\n      <td>13.8</td>\n      <td>0.355</td>\n      <td>...</td>\n      <td>24.7</td>\n      <td>73.0</td>\n      <td>241.0</td>\n      <td>9.5</td>\n      <td>19.6</td>\n      <td>118.7</td>\n      <td>7.2</td>\n      <td>Milwaukee Bucks*</td>\n      <td>15.1</td>\n      <td>51.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020</td>\n      <td>20.6</td>\n      <td>6.1</td>\n      <td>35.1</td>\n      <td>42.2</td>\n      <td>29.3</td>\n      <td>0.514</td>\n      <td>57.1</td>\n      <td>12.9</td>\n      <td>0.377</td>\n      <td>...</td>\n      <td>22.1</td>\n      <td>74.0</td>\n      <td>241.0</td>\n      <td>10.2</td>\n      <td>21.7</td>\n      <td>115.0</td>\n      <td>6.3</td>\n      <td>Portland Trail Blazers*</td>\n      <td>12.8</td>\n      <td>45.3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020</td>\n      <td>21.6</td>\n      <td>5.2</td>\n      <td>34.5</td>\n      <td>40.8</td>\n      <td>25.1</td>\n      <td>0.557</td>\n      <td>45.2</td>\n      <td>15.6</td>\n      <td>0.345</td>\n      <td>...</td>\n      <td>26.1</td>\n      <td>72.0</td>\n      <td>241.4</td>\n      <td>9.8</td>\n      <td>21.8</td>\n      <td>117.8</td>\n      <td>8.7</td>\n      <td>Houston Rockets*</td>\n      <td>14.7</td>\n      <td>44.3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2020</td>\n      <td>23.7</td>\n      <td>4.7</td>\n      <td>37.0</td>\n      <td>41.6</td>\n      <td>29.1</td>\n      <td>0.522</td>\n      <td>55.8</td>\n      <td>12.4</td>\n      <td>0.371</td>\n      <td>...</td>\n      <td>26.3</td>\n      <td>72.0</td>\n      <td>241.4</td>\n      <td>10.7</td>\n      <td>22.1</td>\n      <td>116.3</td>\n      <td>7.1</td>\n      <td>Los Angeles Clippers*</td>\n      <td>14.6</td>\n      <td>47.7</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 25 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "team_tables[2020][\"team_per_game\"].head()"
   ]
  },
  {
   "source": [
    "# Helper functions\n",
    "\n",
    "We will make some functions that will make it easy to use the data we have as we are using a different data structure. We might want to make some queries along multiple tables for example. With this in mind we will make multiple functions that will aide in these kind of common tasks."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(tables, names, years=True, stats=True):\n",
    "    \"\"\"\n",
    "    tables is a nested dictionary representing information by years and then by type of stats\n",
    "    name is a string representing the player or team we want to query\n",
    "    years is list of years we want to look for, if True it looks for all possible years\n",
    "    stats is list of type of stats we want to find, if True it looks for all type of stats\n",
    "\n",
    "    This function will look through all the tables given desired years and stat types and will return a pandas dataframe with all the information that agrees with the search\n",
    "\n",
    "    returns table a pandas dataframe with all results that match the search.\n",
    "    \"\"\"\n",
    "    if isinstance(names, str):\n",
    "        names = [names]\n",
    "    if years == True:\n",
    "        years = tables.keys()\n",
    "    if isinstance(years, int):\n",
    "        years=[years]\n",
    "    if stats == True:\n",
    "        stats = tables[years[0]].keys()\n",
    "    if isinstance(stats, str):\n",
    "        stats = [stats]\n",
    "\n",
    "    \n",
    "    table=pd.DataFrame()\n",
    "    for year in years:\n",
    "        for stat in stats:\n",
    "            data=tables[year][stat]\n",
    "            for name in names:\n",
    "                table=pd.concat([table,data[data[\"name\"]==name]], axis=0)\n",
    "    return table.reset_index(drop=True)\n",
    "\n",
    "def divide_val_set(data, percent=.2):\n",
    "    \"\"\"\n",
    "    data is most likely a dataframe (or list) that has the information we want\n",
    "    percent is a float that selets wanted validation percent\n",
    "\n",
    "    This function takes a given percent and will divide the data into test and validation sets.\n",
    "\n",
    "    returns a test and validation sets.\n",
    "    \"\"\"\n",
    "    n=len(data)\n",
    "    n1=int(n*(1-percent))\n",
    "    return data[:n1], data[n1:]\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Examples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    year          name pos  age team_id   g  gs  mp_per_g  fg_per_g  \\\n",
       "0   2010  James Harden  SG   20     OKC  76   0      22.9       3.1   \n",
       "1   2011  James Harden  SG   21     OKC  82   5      26.7       3.6   \n",
       "2   2012  James Harden  SG   22     OKC  62   2      31.4       5.0   \n",
       "3   2013  James Harden  SG   23     HOU  78  78      38.3       7.5   \n",
       "4   2014  James Harden  SG   24     HOU  73  73      38.0       7.5   \n",
       "5   2015  James Harden  SG   25     HOU  81  81      36.8       8.0   \n",
       "6   2016  James Harden  SG   26     HOU  82  82      38.1       8.7   \n",
       "7   2017  James Harden  PG   27     HOU  81  81      36.4       8.3   \n",
       "8   2018  James Harden  SG   28     HOU  72  72      35.4       9.0   \n",
       "9   2019  James Harden  PG   29     HOU  78  78      36.8      10.8   \n",
       "10  2020  James Harden  SG   30     HOU  68  68      36.5       9.9   \n",
       "\n",
       "    fga_per_g  ...  ft_pct.20  orb_per_g.20  drb_per_g.20  trb_per_g.20  \\\n",
       "0         7.6  ...        NaN           NaN           NaN           NaN   \n",
       "1         8.3  ...        NaN           NaN           NaN           NaN   \n",
       "2        10.1  ...        NaN           NaN           NaN           NaN   \n",
       "3        17.1  ...        NaN           NaN           NaN           NaN   \n",
       "4        16.5  ...        NaN           NaN           NaN           NaN   \n",
       "5        18.1  ...        NaN           NaN           NaN           NaN   \n",
       "6        19.7  ...        NaN           NaN           NaN           NaN   \n",
       "7        18.9  ...        NaN           NaN           NaN           NaN   \n",
       "8        20.1  ...        NaN           NaN           NaN           NaN   \n",
       "9        24.5  ...        NaN           NaN           NaN           NaN   \n",
       "10       22.3  ...      0.865           1.0           5.5           6.6   \n",
       "\n",
       "    ast_per_g.20  stl_per_g.20  blk_per_g.20  tov_per_g.20  pf_per_g.20  \\\n",
       "0            NaN           NaN           NaN           NaN          NaN   \n",
       "1            NaN           NaN           NaN           NaN          NaN   \n",
       "2            NaN           NaN           NaN           NaN          NaN   \n",
       "3            NaN           NaN           NaN           NaN          NaN   \n",
       "4            NaN           NaN           NaN           NaN          NaN   \n",
       "5            NaN           NaN           NaN           NaN          NaN   \n",
       "6            NaN           NaN           NaN           NaN          NaN   \n",
       "7            NaN           NaN           NaN           NaN          NaN   \n",
       "8            NaN           NaN           NaN           NaN          NaN   \n",
       "9            NaN           NaN           NaN           NaN          NaN   \n",
       "10           7.5           1.8           0.9           4.5          3.3   \n",
       "\n",
       "    pts_per_g.20  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "5            NaN  \n",
       "6            NaN  \n",
       "7            NaN  \n",
       "8            NaN  \n",
       "9            NaN  \n",
       "10          34.3  \n",
       "\n",
       "[11 rows x 610 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>name</th>\n      <th>pos</th>\n      <th>age</th>\n      <th>team_id</th>\n      <th>g</th>\n      <th>gs</th>\n      <th>mp_per_g</th>\n      <th>fg_per_g</th>\n      <th>fga_per_g</th>\n      <th>...</th>\n      <th>ft_pct.20</th>\n      <th>orb_per_g.20</th>\n      <th>drb_per_g.20</th>\n      <th>trb_per_g.20</th>\n      <th>ast_per_g.20</th>\n      <th>stl_per_g.20</th>\n      <th>blk_per_g.20</th>\n      <th>tov_per_g.20</th>\n      <th>pf_per_g.20</th>\n      <th>pts_per_g.20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010</td>\n      <td>James Harden</td>\n      <td>SG</td>\n      <td>20</td>\n      <td>OKC</td>\n      <td>76</td>\n      <td>0</td>\n      <td>22.9</td>\n      <td>3.1</td>\n      <td>7.6</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011</td>\n      <td>James Harden</td>\n      <td>SG</td>\n      <td>21</td>\n      <td>OKC</td>\n      <td>82</td>\n      <td>5</td>\n      <td>26.7</td>\n      <td>3.6</td>\n      <td>8.3</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2012</td>\n      <td>James Harden</td>\n      <td>SG</td>\n      <td>22</td>\n      <td>OKC</td>\n      <td>62</td>\n      <td>2</td>\n      <td>31.4</td>\n      <td>5.0</td>\n      <td>10.1</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2013</td>\n      <td>James Harden</td>\n      <td>SG</td>\n      <td>23</td>\n      <td>HOU</td>\n      <td>78</td>\n      <td>78</td>\n      <td>38.3</td>\n      <td>7.5</td>\n      <td>17.1</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2014</td>\n      <td>James Harden</td>\n      <td>SG</td>\n      <td>24</td>\n      <td>HOU</td>\n      <td>73</td>\n      <td>73</td>\n      <td>38.0</td>\n      <td>7.5</td>\n      <td>16.5</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2015</td>\n      <td>James Harden</td>\n      <td>SG</td>\n      <td>25</td>\n      <td>HOU</td>\n      <td>81</td>\n      <td>81</td>\n      <td>36.8</td>\n      <td>8.0</td>\n      <td>18.1</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2016</td>\n      <td>James Harden</td>\n      <td>SG</td>\n      <td>26</td>\n      <td>HOU</td>\n      <td>82</td>\n      <td>82</td>\n      <td>38.1</td>\n      <td>8.7</td>\n      <td>19.7</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2017</td>\n      <td>James Harden</td>\n      <td>PG</td>\n      <td>27</td>\n      <td>HOU</td>\n      <td>81</td>\n      <td>81</td>\n      <td>36.4</td>\n      <td>8.3</td>\n      <td>18.9</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2018</td>\n      <td>James Harden</td>\n      <td>SG</td>\n      <td>28</td>\n      <td>HOU</td>\n      <td>72</td>\n      <td>72</td>\n      <td>35.4</td>\n      <td>9.0</td>\n      <td>20.1</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2019</td>\n      <td>James Harden</td>\n      <td>PG</td>\n      <td>29</td>\n      <td>HOU</td>\n      <td>78</td>\n      <td>78</td>\n      <td>36.8</td>\n      <td>10.8</td>\n      <td>24.5</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2020</td>\n      <td>James Harden</td>\n      <td>SG</td>\n      <td>30</td>\n      <td>HOU</td>\n      <td>68</td>\n      <td>68</td>\n      <td>36.5</td>\n      <td>9.9</td>\n      <td>22.3</td>\n      <td>...</td>\n      <td>0.865</td>\n      <td>1.0</td>\n      <td>5.5</td>\n      <td>6.6</td>\n      <td>7.5</td>\n      <td>1.8</td>\n      <td>0.9</td>\n      <td>4.5</td>\n      <td>3.3</td>\n      <td>34.3</td>\n    </tr>\n  </tbody>\n</table>\n<p>11 rows Ã— 610 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "find(player_tables, \"James Harden\", stats=\"player_per_game\")"
   ]
  },
  {
   "source": [
    "## Test with Neural Nets\n",
    "\n",
    "We will begin testing by using some simple Neural Networks to test our hypotheses. We use an infrastructure that is simple yet specific for our task of predicting a time series so that we can get evidence for what is the best direction to take when building a more complex structure.\n",
    "\n",
    "We will look at predictions made with a model having a few dense layers, really simple one using a RNN and one using an LSTM model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 122 samples\n",
      "122/122 [==============================] - 0s 2ms/sample - loss: 1162.4803\n",
      "Train on 122 samples\n",
      "122/122 [==============================] - 0s 2ms/sample - loss: 567.7068\n",
      "Train on 122 samples\n",
      "122/122 [==============================] - 1s 4ms/sample - loss: 329.8242\n",
      "Train on 122 samples\n",
      "122/122 [==============================] - 1s 8ms/sample - loss: 323.8974\n",
      "dense1 1193.09498339321\n",
      "dense2 591.2075007955557\n",
      "rnn 336.9759569599025\n",
      "lstm 331.5179952403656\n"
     ]
    }
   ],
   "source": [
    "# Create our datasets\n",
    "random.seed(0)\n",
    "\n",
    "names=list(set(player_tables[2019][\"player_per_game\"][\"name\"].tolist())&set(player_tables[2020][\"player_per_game\"][\"name\"].tolist()))\n",
    "names=False\n",
    "for year in range(2015,2021):\n",
    "    if not names:\n",
    "        names=set(player_tables[year][\"player_per_game\"][\"name\"].tolist())\n",
    "    else:\n",
    "        names=names&set(player_tables[year][\"player_per_game\"][\"name\"].tolist())\n",
    "names=list(names)\n",
    "\n",
    "stats=[\"fg_per_g\", \"age\", \"gs\", \"pts_per_g\", \"trb_per_g\", \"ast_per_g\", \"stl_per_g\", \"mp_per_g\", \"blk_per_g\", \"fg3_per_g\"]\n",
    "\n",
    "data=find(player_tables, names, years=2019, stats=\"player_per_game\")[stats]\n",
    "for_rnn=find(player_tables, names, years=range(2015,2020), stats=\"player_per_game\")[stats+[\"name\"]]\n",
    "pred=find(player_tables, names, years=2020, stats=\"player_per_game\")[stats]\n",
    "\n",
    "data_rnn=[]\n",
    "\n",
    "for name in names:\n",
    "    data_rnn.append(for_rnn[for_rnn[\"name\"]==name].drop(columns=[\"name\"]).to_numpy())\n",
    "data_rnn=np.array(data_rnn)\n",
    "\n",
    "test_data, val_data=divide_val_set(data)\n",
    "test_pred, val_pred=divide_val_set(pred)\n",
    "test_data_rnn, val_data_rnn=divide_val_set(data_rnn) \n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "# Dense Layers\n",
    "dense1=tf.keras.Sequential(tf.keras.layers.Dense(10))\n",
    "dense1.compile(loss='mse', optimizer='adam')\n",
    "dense1.fit(test_data.to_numpy(),test_pred.to_numpy())\n",
    "\n",
    "dense2=tf.keras.Sequential([tf.keras.layers.Dense(10), tf.keras.layers.Dense(10)])\n",
    "dense2.compile(loss='mse', optimizer='adam')\n",
    "dense2.fit(test_data.to_numpy(),test_pred.to_numpy())\n",
    "\n",
    "# Simple RNN\n",
    "rnn=tf.keras.Sequential(tf.keras.layers.SimpleRNN(10))\n",
    "rnn.compile(loss='mse', optimizer='adam')\n",
    "rnn.fit(test_data_rnn,test_pred.to_numpy())\n",
    "\n",
    "# LSTM\n",
    "lstm=tf.keras.Sequential(tf.keras.layers.LSTM(10))\n",
    "lstm.compile(loss='mse', optimizer='adam')\n",
    "lstm.fit(test_data_rnn,test_pred.to_numpy())\n",
    "\n",
    "models={\"dense1\":dense1, \"dense2\":dense2, \"rnn\":rnn, \"lstm\":lstm}\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "errors={}\n",
    "for model in models.keys():\n",
    "    if \"dense\" in model:\n",
    "        errors[model]=mean_squared_error(models[model](val_data.to_numpy()), val_pred.to_numpy())\n",
    "    else:\n",
    "        errors[model]=mean_squared_error(models[model](val_data_rnn), val_pred.to_numpy())\n",
    "\n",
    "for model in errors.keys():\n",
    "    print(model, errors[model])"
   ]
  },
  {
   "source": [
    "# Analyzing results\n",
    "\n",
    "We see from the training and from the mean squared error we use to evaluate at the end that the RNN's get better results in this task than a regular NN, also noticing that adding more dense layers performs much better than a single one. We also notice that likely due to the small length of the temporal data the LSTM performs around equal or worse than the simple RNN. Another thing to notice is that the there is a small difference between the loss in the training and validation sets which is evidence that the model is not overfitting. One question we may want to ask is if the reason these models execute better is only because they have information of 5 years or if it is because this is temporal data. We will now test below a dense layer where we have as inputs the data of the 5 years.\n",
    "\n",
    "Note: after running it multiple times the execution of the dense layers has a lot of variance dome models being really close to the RNN's performance (which is consistent) and some having almost 4 times the loss compared to the RNN's."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 122 samples\n",
      "122/122 [==============================] - 0s 2ms/sample - loss: 1311.9737\n",
      "Train on 122 samples\n",
      "122/122 [==============================] - 0s 2ms/sample - loss: 663.6068\n",
      "dense_years1 1325.056512454262\n",
      "dense_years2 585.8374154838968\n"
     ]
    }
   ],
   "source": [
    "data_years=[]\n",
    "for name in names:\n",
    "    data_years.append(for_rnn[for_rnn[\"name\"]==name].drop(columns=[\"name\"]).to_numpy().flatten())\n",
    "data_years=np.array(data_years)\n",
    "\n",
    "test_data_years, val_data_years=divide_val_set(data_years) \n",
    "\n",
    "dense_years1=tf.keras.Sequential(tf.keras.layers.Dense(10))\n",
    "dense_years1.compile(loss='mse', optimizer='adam')\n",
    "dense_years1.fit(test_data_years,test_pred.to_numpy())\n",
    "\n",
    "dense_years2=tf.keras.Sequential([tf.keras.layers.Dense(10),tf.keras.layers.Dense(10)])\n",
    "dense_years2.compile(loss='mse', optimizer='adam')\n",
    "dense_years2.fit(test_data_years,test_pred.to_numpy())\n",
    "\n",
    "print(\"dense_years1\", mean_squared_error(dense_years1(val_data_years), val_pred.to_numpy()))\n",
    "print(\"dense_years2\", mean_squared_error(dense_years2(val_data_years), val_pred.to_numpy()))"
   ]
  },
  {
   "source": [
    "We do not see an improvement, especially up to the level of the RNN using this data where we have now used the information of 5 years to predict the next one. This shows that indeed the temporal structure does provide information that makes for a better prediction."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Comparing team to player data\n",
    "\n",
    "We now want to make a comparison between how well a RNN can predict a team's stats compared with predicting player's stats. The first issue we need to tackle is that the scale of these stats is different and to make a fair comparison we need to normalize our data so that we can compare the execution of our models."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}